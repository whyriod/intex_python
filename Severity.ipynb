{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its alive!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utm\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "print(\"Its alive!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def bin_groups(df, percent=.05):\n",
    "    for col in df:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            for group, count in df[col].value_counts().iteritems():\n",
    "                if count / len(df) < percent:\n",
    "                    df.loc[df[col] == group, col] = 'Other'\n",
    "    return df\n",
    "\n",
    "def fs_variance(df, label=\"\", p=0.8):\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    import pandas as pd\n",
    "\n",
    "    if label != \"\":\n",
    "        X = df.drop(columns=[label])\n",
    "    \n",
    "    sel = VarianceThreshold(threshold=(p * (1 - p)))\n",
    "    sel.fit_transform(X)\n",
    "\n",
    "    # Add the label back in after removing poor features\n",
    "    return df[sel.get_feature_names_out()].join(df[label])\n",
    "\n",
    "def rule(row):\n",
    "    long, lat = utm.to_latlon(row[\"LONG_UTM_X\"], row[\"LAT_UTM_Y\"], 12, 'T')\n",
    "    return pd.Series({\"long\": long, \"lat\": lat})\n",
    "\n",
    "def fit_crossvalidate_clf(df, label, k=10, r=5, repeat=True):\n",
    "    import sklearn.linear_model as lm, pandas as pd, sklearn.ensemble as se, numpy as np\n",
    "    from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
    "    from numpy import mean, std\n",
    "    from sklearn import svm\n",
    "    from sklearn import gaussian_process\n",
    "    from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "    from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "    from sklearn import svm\n",
    "    from sklearn.naive_bayes import CategoricalNB\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    \n",
    "    X = df.drop(columns=[label])\n",
    "    y = df[label]\n",
    "    \n",
    "    if repeat:\n",
    "        cv = RepeatedKFold(n_splits=k, n_repeats=r, random_state=12345)\n",
    "    else:\n",
    "        cv = KFold(n_splits=k, random_state=12345, shuffle=True)\n",
    "    \n",
    "    fit = {}    # Use this to store each of the fit metrics\n",
    "    models = {} # Use this to store each of the models\n",
    "    \n",
    "    # Create the model objects\n",
    "    model_log = lm.LogisticRegression(max_iter=100)\n",
    "    model_logcv = lm.RidgeClassifier()\n",
    "    model_sgd = lm.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "    model_pa = lm.PassiveAggressiveClassifier(max_iter=1000, random_state=12345, tol=1e-3)\n",
    "    model_per = lm.Perceptron(fit_intercept=False, max_iter=10, tol=None, shuffle=False)\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    model_svm = svm.SVC(decision_function_shape='ovo') # Remove the parameter for two-class model\n",
    "    model_nb = CategoricalNB()\n",
    "    model_bag = se.BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "    model_ada = se.AdaBoostClassifier(n_estimators=100, random_state=12345)\n",
    "    model_ext = se.ExtraTreesClassifier(n_estimators=100, random_state=12345)\n",
    "    model_rf = se.RandomForestClassifier(n_estimators=10)\n",
    "    model_hgb = se.HistGradientBoostingClassifier(max_iter=100)\n",
    "    model_vot = se.VotingClassifier(estimators=[('lr', model_log), ('rf', model_ext), ('gnb', model_hgb)], voting='hard')\n",
    "    model_gb = se.GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "    estimators = [('ridge', lm.RidgeCV()), ('lasso', lm.LassoCV(random_state=12345)), ('knr', KNeighborsRegressor(n_neighbors=20, metric='euclidean'))]\n",
    "    final_estimator = se.GradientBoostingRegressor(n_estimators=25, subsample=0.5, min_samples_leaf=25, max_features=1, random_state=12345)\n",
    "    model_st = se.StackingRegressor(estimators=estimators, final_estimator=final_estimator)\n",
    "    model_xgb = XGBClassifier()\n",
    "    model_nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=12345)\n",
    "    \n",
    "    # Fit a cross-validated R squared score and add it to the dict\n",
    "    fit['Logistic'] = mean(cross_val_score(model_log, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['Ridge'] = mean(cross_val_score(model_logcv, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['SGD'] = mean(cross_val_score(model_sgd, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['PassiveAggressive'] = mean(cross_val_score(model_pa, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['Perceptron'] = mean(cross_val_score(model_per, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['KNN'] = mean(cross_val_score(model_knn, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['SVM'] = mean(cross_val_score(model_svm, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['NaiveBayes'] = mean(cross_val_score(model_nb, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['Bagging'] = mean(cross_val_score(model_bag, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['AdaBoost'] = mean(cross_val_score(model_ada, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['ExtraTrees'] = mean(cross_val_score(model_ext, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['RandomForest'] = mean(cross_val_score(model_rf, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['HistGradient'] = mean(cross_val_score(model_hgb, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['Voting'] = mean(cross_val_score(model_vot, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['GradBoost'] = mean(cross_val_score(model_gb, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['XGBoost'] = mean(cross_val_score(model_xgb, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    fit['NeuralN'] = mean(cross_val_score(model_nn, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
    "    \n",
    "    # Add the model to another dictionary; make sure the keys have the same names as the list above\n",
    "    models['Logistic'] = model_log\n",
    "    models['Ridge'] = model_logcv\n",
    "    models['SGD'] = model_sgd\n",
    "    models['PassiveAggressive'] = model_pa\n",
    "    models['Perceptron'] = model_per\n",
    "    models['KNN'] = model_knn\n",
    "    models['SVM'] = model_svm\n",
    "    models['NaiveBayes'] = model_nb\n",
    "    models['Bagging'] = model_bag\n",
    "    models['AdaBoost'] = model_ada\n",
    "    models['ExtraTrees'] = model_ext\n",
    "    models['RandomForest'] = model_rf\n",
    "    models['HistGradient'] = model_hgb\n",
    "    models['Voting'] = model_vot\n",
    "    models['GradBoost'] = model_gb\n",
    "    models['XGBoost'] = model_xgb\n",
    "    models['NeuralN'] = model_nn\n",
    "    \n",
    "    # Add the fit dictionary to a new DataFrame, sort, extract the top row, use it to retrieve the model object from the models dictionary\n",
    "    df_fit = pd.DataFrame({'Accuracy':fit})\n",
    "    df_fit.sort_values(by=['Accuracy'], ascending=False, inplace=True)\n",
    "    best_model = df_fit.index[0]\n",
    "    print(df_fit)\n",
    "    \n",
    "    return models[best_model].fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whyri\\AppData\\Local\\Temp\\ipykernel_17852\\3141534565.py:2: DtypeWarning: Columns (0,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./Utah_Crash_Data_2020.csv\")\n"
     ]
    }
   ],
   "source": [
    "drop_list = []\n",
    "df = pd.read_csv(\"./Utah_Crash_Data_2020.csv\")\n",
    "df = df.drop([\n",
    "\"CRASH_ID\",\n",
    "# \"CRASH_DATETIME\",\n",
    "# \"CRASH_SEVERITY_ID\",\n",
    "# \"ROUTE\",                 //BIN\n",
    "# \"MILEPOINT\",\n",
    "# \"LAT_UTM_Y\",\n",
    "# \"LONG_UTM_X\",\n",
    "\"MAIN_ROAD_NAME\",\n",
    "# \"CITY\",                  //BIN                 \n",
    "# \"COUNTY_NAME\",           //BIN                  \n",
    "# \"WORK_ZONE_RELATED\",                 \n",
    "# \"PEDESTRIAN_INVOLVED\",               \n",
    "# \"BICYCLIST_INVOLVED\",                \n",
    "# \"MOTORCYCLE_INVOLVED\",               \n",
    "# \"IMPROPER_RESTRAINT\",                \n",
    "# \"UNRESTRAINED\",                      \n",
    "# \"DUI\",                               \n",
    "# \"INTERSECTION_RELATED\",              \n",
    "# \"WILD_ANIMAL_RELATED\",               \n",
    "# \"DOMESTIC_ANIMAL_RELATED\",           \n",
    "# \"OVERTURN_ROLLOVER\",                 \n",
    "# \"COMMERCIAL_MOTOR_VEH_INVOLVED\",     \n",
    "# \"TEENAGE_DRIVER_INVOLVED\",           \n",
    "# \"OLDER_DRIVER_INVOLVED\",             \n",
    "# \"NIGHT_DARK_CONDITION\",              \n",
    "# \"SINGLE_VEHICLE\",                    \n",
    "# \"DISTRACTED_DRIVING\",                \n",
    "# \"DROWSY_DRIVING\",                   \n",
    "# \"ROADWAY_DEPARTURE\"\n",
    "], axis=1)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CRASH_MONTH\"] = pd.to_datetime(df[\"CRASH_DATETIME\"]).dt.month\n",
    "df[\"CRASH_WEEKDAY\"] = pd.to_datetime(df[\"CRASH_DATETIME\"]).dt.day_name()\n",
    "df[\"CRASH_HOUR\"] = pd.to_datetime(df[\"CRASH_DATETIME\"]).dt.hour\n",
    "df = df.drop(columns=[\"CRASH_DATETIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, count in df[\"CITY\"].value_counts().iteritems():\n",
    "    if count / len(df) < .02:\n",
    "        df.loc[df[\"CITY\"] == group, \"CITY\"] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, count in df[\"COUNTY_NAME\"].value_counts().iteritems():\n",
    "    if count / len(df) < .02:\n",
    "        df.loc[df[\"COUNTY_NAME\"] == group, \"COUNTY_NAME\"] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, count in df[\"ROUTE\"].value_counts().iteritems():\n",
    "    if count / len(df) < .02:\n",
    "        df.loc[df[\"ROUTE\"] == group, \"ROUTE\"] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(df.apply(rule, axis=1), left_index=True, right_index=True)\n",
    "df = df.drop([\"LAT_UTM_Y\",\"LONG_UTM_X\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MILEPOINT</th>\n",
       "      <th>CRASH_SEVERITY_ID</th>\n",
       "      <th>ROUTE_15</th>\n",
       "      <th>ROUTE_68</th>\n",
       "      <th>ROUTE_80</th>\n",
       "      <th>ROUTE_89</th>\n",
       "      <th>ROUTE_Other</th>\n",
       "      <th>CRASH_MONTH_1</th>\n",
       "      <th>CRASH_MONTH_2</th>\n",
       "      <th>CRASH_MONTH_3</th>\n",
       "      <th>...</th>\n",
       "      <th>NIGHT_DARK_CONDITION_False</th>\n",
       "      <th>NIGHT_DARK_CONDITION_True</th>\n",
       "      <th>SINGLE_VEHICLE_False</th>\n",
       "      <th>SINGLE_VEHICLE_True</th>\n",
       "      <th>DISTRACTED_DRIVING_False</th>\n",
       "      <th>DISTRACTED_DRIVING_True</th>\n",
       "      <th>DROWSY_DRIVING_False</th>\n",
       "      <th>DROWSY_DRIVING_True</th>\n",
       "      <th>ROADWAY_DEPARTURE_False</th>\n",
       "      <th>ROADWAY_DEPARTURE_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.560</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.438</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MILEPOINT  CRASH_SEVERITY_ID  ROUTE_15  ROUTE_68  ROUTE_80  ROUTE_89  \\\n",
       "0      4.560                2.0         0         0         0         0   \n",
       "1      2.702                1.0         0         0         0         0   \n",
       "2      0.351                1.0         0         0         0         0   \n",
       "3      0.438                3.0         0         0         0         0   \n",
       "4      0.796                1.0         0         0         0         0   \n",
       "\n",
       "   ROUTE_Other  CRASH_MONTH_1  CRASH_MONTH_2  CRASH_MONTH_3  ...  \\\n",
       "0            1              0              1              0  ...   \n",
       "1            1              0              0              0  ...   \n",
       "2            1              0              0              0  ...   \n",
       "3            1              0              0              0  ...   \n",
       "4            1              0              0              0  ...   \n",
       "\n",
       "   NIGHT_DARK_CONDITION_False  NIGHT_DARK_CONDITION_True  \\\n",
       "0                           1                          0   \n",
       "1                           1                          0   \n",
       "2                           0                          1   \n",
       "3                           0                          1   \n",
       "4                           0                          1   \n",
       "\n",
       "   SINGLE_VEHICLE_False  SINGLE_VEHICLE_True  DISTRACTED_DRIVING_False  \\\n",
       "0                     1                    0                         1   \n",
       "1                     1                    0                         1   \n",
       "2                     1                    0                         1   \n",
       "3                     0                    1                         1   \n",
       "4                     1                    0                         1   \n",
       "\n",
       "   DISTRACTED_DRIVING_True  DROWSY_DRIVING_False  DROWSY_DRIVING_True  \\\n",
       "0                        0                     1                    0   \n",
       "1                        0                     1                    0   \n",
       "2                        0                     1                    0   \n",
       "3                        0                     1                    0   \n",
       "4                        0                     1                    0   \n",
       "\n",
       "   ROADWAY_DEPARTURE_False  ROADWAY_DEPARTURE_True  \n",
       "0                        0                       1  \n",
       "1                        1                       0  \n",
       "2                        1                       0  \n",
       "3                        1                       0  \n",
       "4                        1                       0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=[\n",
    "    \"ROUTE\",\n",
    "    \"CRASH_MONTH\",\n",
    "    \"CRASH_WEEKDAY\",\n",
    "    \"CRASH_HOUR\",\n",
    "    \"CITY\",\n",
    "    \"COUNTY_NAME\",\n",
    "    \"WORK_ZONE_RELATED\",                 \n",
    "    \"PEDESTRIAN_INVOLVED\",               \n",
    "    \"BICYCLIST_INVOLVED\",                \n",
    "    \"MOTORCYCLE_INVOLVED\",               \n",
    "    \"IMPROPER_RESTRAINT\",                \n",
    "    \"UNRESTRAINED\",                      \n",
    "    \"DUI\",                               \n",
    "    \"INTERSECTION_RELATED\",              \n",
    "    \"WILD_ANIMAL_RELATED\",               \n",
    "    \"DOMESTIC_ANIMAL_RELATED\",           \n",
    "    \"OVERTURN_ROLLOVER\",                 \n",
    "    \"COMMERCIAL_MOTOR_VEH_INVOLVED\",     \n",
    "    \"TEENAGE_DRIVER_INVOLVED\",           \n",
    "    \"OLDER_DRIVER_INVOLVED\",             \n",
    "    \"NIGHT_DARK_CONDITION\",              \n",
    "    \"SINGLE_VEHICLE\",                    \n",
    "    \"DISTRACTED_DRIVING\",                \n",
    "    \"DROWSY_DRIVING\",                   \n",
    "    \"ROADWAY_DEPARTURE\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\whyri\\OneDrive\\Desktop\\intex_python\\ml-venv2\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "df_new = fs_variance(df, label=\"CRASH_SEVERITY_ID\", p=.8)\n",
    "# model = fit_crossvalidate_clf(df, \"SaleCondition\", 5, 2)\n",
    "model = fit_crossvalidate_clf(df_new, \"CRASH_SEVERITY_ID\", 5, 2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87b4b0f85ae28ec6fce2f0c0cb1d79c52d31810894d956546345bdbc51c8189b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ml-venv2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
